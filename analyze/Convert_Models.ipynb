{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f358d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 17:53:17.221872: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-13 17:53:17.221980: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e05c690",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7virbm2f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7virbm2f/assets\n",
      "2022-04-13 17:54:10.716022: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
      "2022-04-13 17:54:10.716096: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
      "2022-04-13 17:54:10.716348: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp7virbm2f\n",
      "2022-04-13 17:54:10.719577: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-04-13 17:54:10.719609: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/tmp7virbm2f\n",
      "2022-04-13 17:54:10.744262: I tensorflow/cc/saved_model/loader.cc:210] Restoring SavedModel bundle.\n",
      "2022-04-13 17:54:10.798509: I tensorflow/cc/saved_model/loader.cc:194] Running initialization op on SavedModel bundle at path: /tmp/tmp7virbm2f\n",
      "2022-04-13 17:54:10.824567: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 108221 microseconds.\n",
      "2022-04-13 17:54:11.083353: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1891] TFLite interpreter neeWARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "ds to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListFromTensor, FlexTensorListGetItem, FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListFromTensor(tensor<5x?x3xf32>, tensor<2xi32>) -> (tensor<!tf_type.variant<tensor<?x3xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListGetItem(tensor<!tf_type.variant<tensor<?x3xf32>>>, tensor<i32>, tensor<2xi32>) -> (tensor<?x3xf32>) : {device = \"\"}\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x8xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x8xf32>>>, tensor<i32>, tensor<?x8xf32>) -> (tensor<!tf_type.variant<tensor<?x8xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x8xf32>>>, tensor<2xi32>) -> (tensor<?x?x8xf32>) : {device = \"\", num_elements = -1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "model_name = 'best_model_ever'\n",
    "\n",
    "model = tf.keras.models.load_model(f'./{model_name}.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'{model_name}.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bce468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daa27e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 18:00:52.553412: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-13 18:00:52.553466: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "2022-04-13 18:00:54.668068: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-13 18:00:54.668743: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-13 18:00:54.668772: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-13 18:00:54.668795: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (penguin): /proc/driver/nvidia/version does not exist\n",
      "INFO: TfLiteFlexDelegate delegate: 3 nodes delegated out of 13 nodes with 2 partitions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.lite as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter('best_model_ever.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f762045f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06695357]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.array([[[0,0,0] for _ in range(5)]], dtype='float32')\n",
    "print(inp)\n",
    "interpreter.set_tensor(input_details[0]['index'], inp)\n",
    "interpreter.invoke()\n",
    "interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55e130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
